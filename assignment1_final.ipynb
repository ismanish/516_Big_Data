{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0e5d053192af037371a85cdcc9c59e5",
     "grade": false,
     "grade_id": "cell-56105c53b6205093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SIADS 516: Homework 1\n",
    "\n",
    "- **Dr. Chris Teplovs**, School of Information, University of Michigan\n",
    "- **Kris Steinhoff**, School of Information, University of Michigan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e18d3521b1e1eb4f1afb1d8e9c36d816",
     "grade": false,
     "grade_id": "cell-6bd8f47091729e22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The AutograderHelper class provides methods used by the autograder.\n",
    "from autograder_helper import AutograderHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0477ef5614295bf8caf6e1096266bfa3",
     "grade": true,
     "grade_id": "inject_private_helper",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 0 points.\n",
    "# This cell has hidden code used to configure the autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f91d5cc70e3d29b469bae2ec891c5d82",
     "grade": false,
     "grade_id": "cell-1be2e789f3e3b2ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## -- WORD COUNT -- \n",
    "\n",
    "### Our first mrjob script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90776fd984b2495e525165c3b22a7fd5",
     "grade": false,
     "grade_id": "cell-5fb564afc49d95b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall the following example from the lectures:\n",
    "\n",
    "Note the use of the magic command ```%%file```.  You can use this to write the contents of a cell out to a file, which is what we need to do to use mrjob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "066e857d51624d13271bd6bc0d48a6d1",
     "grade": false,
     "grade_id": "cell-5bbe26b3f42bdf59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'word_count_output_short.tsv'\r\n",
      "removed 'word_count.py'\r\n"
     ]
    }
   ],
   "source": [
    "# Clean up previous versions of word_count.py and its output files\n",
    "!rm -f -v word_count*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc5eb381f21a91bd8aed66efe7dc6de8",
     "grade": false,
     "grade_id": "cell-88ddb7e015817c7d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word_count.py\n"
     ]
    }
   ],
   "source": [
    "%%file word_count.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "  ### input: self, in_key, in_value\n",
    "  def mapper(self, _, line):\n",
    "    yield \"chars\", len(line)\n",
    "    yield \"words\", len(line.split())\n",
    "    yield \"lines\", 1\n",
    "\n",
    "  ### input: self, in_key from mapper, in_value from mapper\n",
    "  def reducer(self, key, values):\n",
    "    yield key, sum(values)\n",
    "if __name__ == \"__main__\":\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e29c48b830c9091271fda48ef0e389f",
     "grade": false,
     "grade_id": "cell-97cd355074269541",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's look at the output of running the script with that file. Note that we are using the `tee` command here to make things easier for the autograder. The `|` character sends the output of our script to the `tee` command which prints it to the display, and also writes the script output to the given file name (\"file_stats_output.tsv\" in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e761f904b8e7bf5bbf0625c44d1ed8c7",
     "grade": false,
     "grade_id": "cell-6513df9792070425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/word_count.jovyan.20220707.143742.841936\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/word_count.jovyan.20220707.143742.841936/output\n",
      "Streaming final output from /tmp/word_count.jovyan.20220707.143742.841936/output...\n",
      "\"lines\"\t200\n",
      "\"words\"\t1822\n",
      "\"chars\"\t10653\n",
      "Removing temp directory /tmp/word_count.jovyan.20220707.143742.841936...\n"
     ]
    }
   ],
   "source": [
    "!python word_count.py ../../assets/data/gutenberg/short.t1.txt | tee word_count_output_short.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22fdd4bcc28a64cb016b47b887142ec7",
     "grade": false,
     "grade_id": "cell-4628321c63ed9381",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell deliberately includes answers to provide guidance on how questions in this assignment are graded.\n",
    "\n",
    "correct = AutograderHelper.parse_mrjob_output(\"\"\"\n",
    "\"chars\"\t10653\n",
    "\"lines\"\t200\n",
    "\"words\"\t1822\n",
    "\"\"\".strip().split(\"\\n\"))\n",
    "\n",
    "submitted = AutograderHelper.parse_mrjob_output_file(\"word_count_output_short.tsv\")\n",
    "\n",
    "AutograderHelper.assert_same_shape(correct, submitted)\n",
    "AutograderHelper.assert_same_rows(correct, submitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32b1757389d99e22f2236fe7d86d43f4",
     "grade": false,
     "grade_id": "cell-ccebe5e2546f59ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## -- MOST-USED WORD --\n",
    "\n",
    "\n",
    "A note about word splitting:\n",
    "\n",
    "The `split()` method used in the example above, breaks on white space and there are cases where this isn't ideal:\n",
    "\n",
    "```python\n",
    "\"My dog--Luna--is barking\".split()         # --> ['My', 'dog--Luna--is', 'barking']\n",
    "```\n",
    "\n",
    "So in the following exercises, we will use a regular expression to split words instead. Note that the starter code below provides a function `splitter()`. We can use this to get better word splitting:\n",
    "\n",
    "```python\n",
    "splitter(\"My dog--Luna--is barking\")       # --> ['My', 'dog', 'Luna', 'is', 'barking']\n",
    "```\n",
    "\n",
    "### Task: Complete the most-used word count implementation\n",
    "\n",
    "Your task in this exercise is to complete the implementation of the `mapper_get_words()` method below. It should:\n",
    "- Use `splitter()` function to split words\n",
    "- Yield 2-tuples that are key-value pairs, where the key (first item in the tuple) is the word to be counted.\n",
    "- Only yield for words that are NOT in the STOPWORDS set\n",
    "- This should be case insensitive, meaning that, for example, \"Dog\" and \"dog\" will be processed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29ba0284d557291a214d4f2f78cd7037",
     "grade": false,
     "grade_id": "cell-400bd2c427474552",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**A note about debugging in this context...**\n",
    "\n",
    "- **Use `debug()` instead of `print()`** Since we are running these MRJob scripts and capturing their output for grading, if you use the standard print() function for debugging, your message will end up in the data output which will corrupt the results. So instead use the debug() function that is defined at the top of the starter code for each of the scripts below. It works mostly like print() does, but its output goes to the stderr interface instead of stdout. This means you'll see it like a normal print() in the output of a notebook cell, but those message won't end up in the data output.\n",
    "- **Double check the data output** If you are getting unexpected results from the grader, one thing to double check is the output date file directly. For example, the first output file by this notebook is \"word_count_output_short.tsv\" (above). You can open that file and make sure its contents are what you would expect (in that case three lines with the keys \"chars\", \"lines\", and \"words\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "757e8d3ef9056d3080743b54f8ec63b6",
     "grade": false,
     "grade_id": "cell-2e2efce2460c6c89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'most_used_word_output_lewis.tsv'\r\n",
      "removed 'most_used_word_output_shakespeare.tsv'\r\n",
      "removed 'most_used_word.py'\r\n"
     ]
    }
   ],
   "source": [
    "# Clean up previous versions of most_used_word.py and its output files\n",
    "!rm -f -v most_used_word*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be36495b80954969c96e8881ee2d1b62",
     "grade": false,
     "grade_id": "cell-7aae180d3964cc94",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing most_used_word.py\n"
     ]
    }
   ],
   "source": [
    "%%file most_used_word.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "from sys import stderr\n",
    "\n",
    "# See the note above about debugging\n",
    "def debug(*msg, **kwargs):\n",
    "    \"\"\"Print debugging message to standard error.\"\"\"\n",
    "    print(*msg, file=stderr, **kwargs)\n",
    "    \n",
    "    \n",
    "def splitter(text):\n",
    "    WORD_RE = re.compile(r\"[\\w']+\")\n",
    "    return WORD_RE.findall(text)\n",
    "\n",
    "\n",
    "STOPWORDS = {\n",
    "    'i', 'we', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during',\n",
    "    'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such',\n",
    "    'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each',\n",
    "    'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me',\n",
    "    'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up',\n",
    "    'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been',\n",
    "    'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so',\n",
    "    'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself',\n",
    "    'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by',\n",
    "    'doing', 'it', 'how', 'further', 'was', 'here', 'than'\n",
    "}\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word)\n",
    "        ]\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # YOUR CODE HERE\n",
    "        for word in splitter(line.lower()):\n",
    "            if word not in STOPWORDS:\n",
    "                yield(word.lower(),1)\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is used so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start = time.time()\n",
    "    MRMostUsedWord.run()\n",
    "    end = time.time()\n",
    "    debug(\"Run time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb9eadf7560f9af09d39d3942e9f1ebc",
     "grade": false,
     "grade_id": "cell-c08d3814aa9faecf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's run this script on a small file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "224daead7f10fca740a845431a0450e9",
     "grade": false,
     "grade_id": "cell-95ca97c49ce98d7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/most_used_word.jovyan.20220707.143745.124983\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/most_used_word.jovyan.20220707.143745.124983/output\n",
      "Streaming final output from /tmp/most_used_word.jovyan.20220707.143745.124983/output...\n",
      "1334\t\"river\"\n",
      "Removing temp directory /tmp/most_used_word.jovyan.20220707.143745.124983...\n",
      "Run time: 1.7497541904449463 seconds\n"
     ]
    }
   ],
   "source": [
    "!python most_used_word.py ../../assets/data/gutenberg/t3.lewis.txt | tee most_used_word_output_lewis.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "587ae1ba7b28fd60bf7724bab8a13b26",
     "grade": true,
     "grade_id": "cell-63ce881911b6e7e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 1 point (out of 20). This cell does not contain hidden tests.\n",
    "# This cell deliberately includes answers to provide guidance on how this question is graded.\n",
    "\n",
    "correct = AutograderHelper.parse_mrjob_output(\"\"\"\n",
    "1334\t\"river\"\n",
    "\"\"\".strip().split(\"\\n\"))\n",
    "\n",
    "submitted = AutograderHelper.parse_mrjob_output_file(\"most_used_word_output_lewis.tsv\")\n",
    "\n",
    "AutograderHelper.assert_same_shape(correct, submitted)\n",
    "AutograderHelper.assert_same_rows(correct, submitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16a59fc0fa52091d266d73fede2f6696",
     "grade": false,
     "grade_id": "cell-4d087c4d82c33a32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's run this script on a larger file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ce30dc6ec73cfe8fb583166eeb4b5f6",
     "grade": false,
     "grade_id": "cell-0ffbecc33342e767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/most_used_word.jovyan.20220707.143747.624065\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/most_used_word.jovyan.20220707.143747.624065/output\n",
      "Streaming final output from /tmp/most_used_word.jovyan.20220707.143747.624065/output...\n",
      "5479\t\"thou\"\n",
      "Removing temp directory /tmp/most_used_word.jovyan.20220707.143747.624065...\n",
      "Run time: 4.333291292190552 seconds\n"
     ]
    }
   ],
   "source": [
    "!python most_used_word.py ../../assets/data/gutenberg/t8.shakespeare.txt | tee most_used_word_output_shakespeare.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "926e98c61a0c834f97d6c443cbcc30bc",
     "grade": false,
     "grade_id": "cell-a47d4ffe5034c678",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "submitted = AutograderHelper.parse_mrjob_output_file(\"most_used_word_output_shakespeare.tsv\")\n",
    "\n",
    "assert len(submitted) == 1, \\\n",
    "    \"The submission is not the correct length.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19341f8ce33650c300d3a058b1bd13f4",
     "grade": true,
     "grade_id": "cell-48b4d1443b4285b1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 5 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ac8a2676e296f7854198f36760309a7",
     "grade": false,
     "grade_id": "cell-56bddb381ba2d790",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## -- SYLLABLE COUNT --\n",
    "\n",
    "The [`syllables` package](https://pypi.org/project/syllables/) (which is pre-installed for you) has an `estimate()` method you can use to get an estimated count of syllables for a given word.\n",
    "\n",
    "A couple of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2aa890107fd75edcfe98a110fcf927a",
     "grade": false,
     "grade_id": "cell-c28602a80f249afa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import syllables\n",
    "\n",
    "syllables.estimate(\"funny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23f346d6cdc1ceb6e77d665d567c441e",
     "grade": false,
     "grade_id": "cell-5466c182b130d3b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables.estimate(\"strengths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0ed4f1863a54ba1a3af0b6722bf0cc6",
     "grade": false,
     "grade_id": "cell-166f93c72508122b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "These are just estimates, so you'll see inaccurate counts from this package, for example, with \"temperature\". Don't worry about this. For this exercise, we just care about the result from `syllables.estimate()`, not how accurate it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1abb1985daa2cfc412b38a3aa2103f6f",
     "grade": false,
     "grade_id": "cell-db27a29d71468f3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables.estimate(\"temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb567ece6b3edf1e5917caa8a7e0aa81",
     "grade": false,
     "grade_id": "cell-81efcca96dd5b9a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task: Write an MRJob script\n",
    "\n",
    "Your task is to write a MRJob script that finds the 10 words that have the most syllables from the input file. This top-ten list should be sorted first by the syllable count, then by the word in alphabetic order. It should:\n",
    "\n",
    "- Use the `splitter()` function to split words\n",
    "- Only process words that are NOT in the STOPWORDS set\n",
    "- This should be case insensitive, meaning that, for example, \"Dog\" and \"dog\" will be processed together.\n",
    "- Use the `sort_results()` function (see below) to sort the final results.\n",
    "\n",
    "**Sorting the Results** In order to simplify interpretation of the results, use the provided `sort_results()` function. For example: if our input is:\n",
    "\n",
    "```\n",
    "The dog sleeps by the fireplace.\n",
    "```\n",
    "\n",
    "and our mapper gives us a result like this:\n",
    "\n",
    "```\n",
    "[\n",
    "    (1, \"dog\"),\n",
    "    (3, \"fireplace\"),\n",
    "    (1, \"the\"),\n",
    "    (1, \"sleeps\"),\n",
    "    (1, \"by\"),\n",
    "]\n",
    "```\n",
    "\n",
    "The `sort_results()` function will sort that like this:\n",
    "\n",
    "```\n",
    "[\n",
    "    (3, \"fireplace\"),\n",
    "    (1, \"by\"),\n",
    "    (1, \"dog\"),\n",
    "    (1, \"sleeps\"),\n",
    "    (1, \"the\"),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49fa84f3a027556836c01ee5d2c9e029",
     "grade": false,
     "grade_id": "cell-a17bf1b49f93695c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'top_10_syllable_count_output_churchill.tsv'\r\n",
      "removed 'top_10_syllable_count_output_short.tsv'\r\n",
      "removed 'top_10_syllable_count.py'\r\n"
     ]
    }
   ],
   "source": [
    "# Clean up previous versions of top_10_syllable_count.py and its output files\n",
    "!rm -f -v top_10_syllable_count*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "630dc49009164ab4fb8df582a1b36a26",
     "grade": false,
     "grade_id": "cell-fd70738103ee29bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing top_10_syllable_count.py\n"
     ]
    }
   ],
   "source": [
    "%%file top_10_syllable_count.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "from sys import stderr\n",
    "\n",
    "import syllables\n",
    "\n",
    "\n",
    "# See the note above about debugging\n",
    "def debug(*msg, **kwargs):\n",
    "    \"\"\"Print debugging message to standard error.\"\"\"\n",
    "    print(*msg, file=stderr, **kwargs)\n",
    "    \n",
    "\n",
    "def splitter(text):\n",
    "    WORD_RE = re.compile(r\"[\\w']+\")\n",
    "    return WORD_RE.findall(text)\n",
    "\n",
    "\n",
    "def sort_results(results):\n",
    "    \"\"\"\n",
    "    Sorts a list of 2-tuples descending by the first value in the \n",
    "    tuple, ascending by the second value in the tuple.\n",
    "    \"\"\"\n",
    "    return sorted(results, key=lambda k: (-k[0], k[1]))\n",
    "\n",
    "\n",
    "STOPWORDS = {\n",
    "    'i', 'we', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during',\n",
    "    'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such',\n",
    "    'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each',\n",
    "    'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me',\n",
    "    'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up',\n",
    "    'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been',\n",
    "    'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so',\n",
    "    'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself',\n",
    "    'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by',\n",
    "    'doing', 'it', 'how', 'further', 'was', 'here', 'than'\n",
    "}\n",
    "\n",
    "\n",
    "class MRTopUsedWord(MRJob):    \n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   reducer = self.reducer_count_words),\n",
    "            MRStep(reducer = self.reducer_find_top_words)\n",
    "            \n",
    "        ]\n",
    "                   \n",
    "\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # YOUR CODE HERE\n",
    "        for word in splitter(line.lower()):\n",
    "            if word not in STOPWORDS:\n",
    "                yield(word.lower(),syllables.estimate(word.lower()))\n",
    "        \n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        s=0\n",
    "        c=0\n",
    "        for p in counts:\n",
    "            s= s+p\n",
    "            c = c+1\n",
    "        yield None, (int(s/c), word)\n",
    "        \n",
    "        \n",
    "    def reducer_find_top_words(self, _, word_count_pairs):\n",
    "        for i, word in sort_results(word_count_pairs)[:10]:\n",
    "            yield (i,word)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start = time.time()\n",
    "    MRTopUsedWord.run()\n",
    "    end = time.time()\n",
    "    debug(\"Run time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dde6fefdecfae37940c5037644b8fadf",
     "grade": false,
     "grade_id": "cell-d94830239a048c0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's run this script on a small file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4333844825d18960b8f878d15b7be068",
     "grade": false,
     "grade_id": "cell-7e4d9f8ca76d9727",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/top_10_syllable_count.jovyan.20220707.143753.522244\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/top_10_syllable_count.jovyan.20220707.143753.522244/output\n",
      "Streaming final output from /tmp/top_10_syllable_count.jovyan.20220707.143753.522244/output...\n",
      "6\t\"phonotelephote\"\n",
      "6\t\"plenipotentiaries\"\n",
      "6\t\"revolutionized\"\n",
      "6\t\"unfortunately\"\n",
      "6\t\"unimaginable\"\n",
      "5\t\"accumulator\"\n",
      "5\t\"accumulators\"\n",
      "5\t\"agriculture\"\n",
      "5\t\"civilization\"\n",
      "5\t\"communicate\"\n",
      "Removing temp directory /tmp/top_10_syllable_count.jovyan.20220707.143753.522244...\n",
      "Run time: 0.9957668781280518 seconds\n"
     ]
    }
   ],
   "source": [
    "!python top_10_syllable_count.py ../../assets/data/gutenberg/short.t1.txt | tee top_10_syllable_count_output_short.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = AutograderHelper.parse_mrjob_output(\"\"\"\n",
    "6\t\"phonotelephote\"\n",
    "6\t\"plenipotentiaries\"\n",
    "6\t\"revolutionized\"\n",
    "6\t\"unfortunately\"\n",
    "6\t\"unimaginable\"\n",
    "5\t\"accumulator\"\n",
    "5\t\"accumulators\"\n",
    "5\t\"agriculture\"\n",
    "5\t\"civilization\"\n",
    "5\t\"communicate\"\n",
    "\"\"\".strip().split(\"\\n\"))\n",
    "correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitted = AutograderHelper.parse_mrjob_output_file(\"top_10_syllable_count_output_short.tsv\")\n",
    "submitted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd52f833172e44d27b6a518d9260b967",
     "grade": true,
     "grade_id": "cell-55b6712e9c002d57",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 2 points (out of 20). This cell does not contain hidden tests.\n",
    "# This cell deliberately includes answers to provide guidance on how this question is graded.\n",
    "\n",
    "correct = AutograderHelper.parse_mrjob_output(\"\"\"\n",
    "6\t\"phonotelephote\"\n",
    "6\t\"plenipotentiaries\"\n",
    "6\t\"revolutionized\"\n",
    "6\t\"unfortunately\"\n",
    "6\t\"unimaginable\"\n",
    "5\t\"accumulator\"\n",
    "5\t\"accumulators\"\n",
    "5\t\"agriculture\"\n",
    "5\t\"civilization\"\n",
    "5\t\"communicate\"\n",
    "\"\"\".strip().split(\"\\n\"))\n",
    "\n",
    "submitted = AutograderHelper.parse_mrjob_output_file(\"top_10_syllable_count_output_short.tsv\")\n",
    "\n",
    "AutograderHelper.assert_same_shape(correct, submitted)\n",
    "AutograderHelper.assert_same_rows(correct, submitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b45bbd194e525df8208e46c892e75b5",
     "grade": false,
     "grade_id": "cell-23f277c9de1b4246",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's run this script on a larger file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e95670309a64b455b48225e10053a62",
     "grade": false,
     "grade_id": "cell-a9905ce269b842ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/top_10_syllable_count.jovyan.20220707.143755.429400\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in /tmp/top_10_syllable_count.jovyan.20220707.143755.429400/output\n",
      "Streaming final output from /tmp/top_10_syllable_count.jovyan.20220707.143755.429400/output...\n",
      "8\t\"incommunicability\"\n",
      "8\t\"overcapitalization\"\n",
      "7\t\"apologetically\"\n",
      "7\t\"authoritatively\"\n",
      "7\t\"characteristically\"\n",
      "7\t\"communicativeness\"\n",
      "7\t\"corroboratively\"\n",
      "7\t\"disproportionately\"\n",
      "7\t\"imaginatively\"\n",
      "7\t\"impenetrability\"\n",
      "Removing temp directory /tmp/top_10_syllable_count.jovyan.20220707.143755.429400...\n",
      "Run time: 31.287047624588013 seconds\n"
     ]
    }
   ],
   "source": [
    "!python top_10_syllable_count.py ../../assets/data/gutenberg/t5.churchill.txt | tee top_10_syllable_count_output_churchill.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4a6006077696f4a96824fea9ded6e5",
     "grade": false,
     "grade_id": "cell-32f60cf29b9ed28d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "submitted = AutograderHelper.parse_mrjob_output_file(\"top_10_syllable_count_output_churchill.tsv\")\n",
    "\n",
    "assert len(submitted) == 10, \\\n",
    "    \"The submission is not the correct length.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "593d57ce63190b79c2a9e33b44784858",
     "grade": true,
     "grade_id": "cell-56a13e31959aa8ea",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder cell. This cell is worth 12 points (out of 20). This cell contains hidden tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_big_data_scalable_data_processing_v3_assignment1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
